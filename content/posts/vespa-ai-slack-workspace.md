---
title: "Vespa AI Slack Workspace"
date: 2022-03-24T19:59:56-07:00
draft: true
---

_I joined the [Vespa](https://vespa.ai) public slack workspace and posted this question in #general._

#### Question

TLDR: Teach me about when retrieval is important, and anything else relevant in the world of embeddings: creating them, scoring their similarity, ranking their relevance

> Hi, I am trying to learn the difference among several solutions in the market right now, and realizing that clever solutions for retrieval is necessary when scaling. Primarily, is the thing that is “hard” the ability to scale out approx nearest neighbor search to millions of vectors? I saw there is Vespa, Weaviate, Pinecone, and even elasticsearch offers some embedding options and asks you to select a distance/similarity metric. After speaking with a colleague of mine, they mentioned how retrieval is only one part of the problem, and they said it’s easy/fast when there are just hundreds of thousands of vectors. Can you direct me to some reading materials that discusses deeper things, such as learning a similarity metric, building useful embeddings? Also, when retrieving items based on a query (like one of your examples is searching across 20+ million dense Wikipedia passages), is nearest neighbor also the right metric for ranking results? I guess what I am getting at is that for personalized search results, there’s a lot to consider and I wanted to understand where I could learn more to go deeper. Thank you!


#### Summary of their 

{{< highlight html >}}
<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>Example HTML5 Document</title>
</head>
<body>
  <p>Test</p>
</body>
</html>
{{< /highlight >}}
